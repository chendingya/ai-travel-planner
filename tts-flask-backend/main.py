import os
import json
from flask import Flask, request, jsonify
from flask_cors import CORS
import dashscope
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®DashScope API URL
dashscope.base_http_api_url = 'https://dashscope.aliyuncs.com/api/v1'

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({'status': 'ok'})

@app.route('/api/tts', methods=['POST'])
def text_to_speech():
    """æ–‡å­—è½¬è¯­éŸ³API"""
    try:
        data = request.get_json()
        
        # è·å–è¯·æ±‚å‚æ•°
        text = data.get('text', '')
        voice = data.get('voice', 'Cherry')
        language_type = data.get('language_type', 'Chinese')
        
        if not text:
            return jsonify({
                'error': 'Missing text',
                'message': 'è¯·æä¾›è¦è½¬æ¢çš„æ–‡æœ¬å†…å®¹'
            }), 400
        
        # æ£€æŸ¥API Key
        api_key = os.getenv('DASHSCOPE_API_KEY')
        tts_model = os.getenv('DASHSCOPE_TTS_MODEL', 'qwen3-tts-flash')
        if not api_key:
            return jsonify({
                'error': 'TTSåŠŸèƒ½ä¸å¯ç”¨',
                'message': 'ç³»ç»Ÿç®¡ç†å‘˜éœ€è¦é…ç½®DashScope APIå¯†é’¥æ‰èƒ½ä½¿ç”¨è¯­éŸ³åˆæˆåŠŸèƒ½'
            }), 500
        
        print(f"ğŸ—£ï¸ æ­£åœ¨è°ƒç”¨é€šä¹‰åƒé—®TTS API...")
        print(f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        print(f"ğŸ¤ éŸ³è‰²: {voice}")
        print(f"ğŸŒ è¯­è¨€: {language_type}")
        
        # è°ƒç”¨DashScope TTS API
        response = dashscope.MultiModalConversation.call(
            model=tts_model,
            api_key=api_key,
            text=text,
            voice=voice,
            language_type=language_type,
            stream=False
        )
        
        print(f"âœ… TTSä»»åŠ¡åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“‹ å“åº”å†…å®¹: {response}")
        
        return jsonify({
            'taskId': response.output.task_id,
            'model': tts_model,
            'voice': voice,
            'language_type': language_type,
            'text_length': len(text)
        })
        
    except Exception as error:
        print(f"âŒ Error calling TTS API: {error}")
        
        error_message = 'è¯­éŸ³åˆæˆæ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•'
        
        # å¤„ç†ç‰¹å®šé”™è¯¯ç±»å‹
        if hasattr(error, 'code'):
            if error.code == 'InvalidParameter':
                error_message = 'è¯·æ±‚å‚æ•°æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ–‡æœ¬å†…å®¹å’ŒéŸ³è‰²è®¾ç½®'
            elif error.code == 'InvalidApiKey':
                error_message = 'APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®'
            elif error.code == 'QuotaExceeded':
                error_message = 'TTSé…é¢å·²ç”¨å®Œï¼Œè¯·ç¨åå†è¯•'
            elif error.code == 'TextTooLong':
                error_message = 'æ–‡æœ¬è¿‡é•¿ï¼Œè¯·åˆ†æ®µå¤„ç†'
            else:
                error_message = error.message or error_message
        else:
            error_message = str(error) or error_message
        
        return jsonify({
            'error': 'Failed to synthesize speech',
            'message': error_message,
            'code': getattr(error, 'code', None)
        }), 500

@app.route('/api/tts/audio/<task_id>', methods=['GET'])
def get_tts_audio(task_id):
    """è·å–TTSéŸ³é¢‘æ–‡ä»¶"""
    try:
        if not task_id:
            return jsonify({
                'error': 'Missing taskId',
                'message': 'è¯·æä¾›ä»»åŠ¡ID'
            }), 400
        
        print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢TTSä»»åŠ¡çŠ¶æ€: {task_id}")
        
        # æ£€æŸ¥API Key
        api_key = os.getenv('DASHSCOPE_API_KEY')
        tts_model = os.getenv('DASHSCOPE_TTS_MODEL', 'qwen3-tts-flash')
        if not api_key:
            return jsonify({
                'error': 'TTSåŠŸèƒ½ä¸å¯ç”¨',
                'message': 'ç³»ç»Ÿç®¡ç†å‘˜éœ€è¦é…ç½®DashScope APIå¯†é’¥æ‰èƒ½ä½¿ç”¨è¯­éŸ³åˆæˆåŠŸèƒ½'
            }), 500
        
        # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
        response = dashscope.MultiModalConversation.call(
            model=tts_model,
            api_key=api_key,
            input={'task_id': task_id}
        )
        
        if not response or not response.output:
            raise Exception('TTSçŠ¶æ€æŸ¥è¯¢å¤±è´¥')
        
        task_status = response.output.task_status
        
        if task_status == 'SUCCEED':
            audio_url = response.output.audio_url
            print(f"âœ… TTSä»»åŠ¡å®Œæˆï¼ŒéŸ³é¢‘URL: {audio_url}")
            
            return jsonify({
                'status': 'completed',
                'audio_url': audio_url,
                'task_id': task_id
            })
        elif task_status == 'FAILED':
            error_msg = response.output.message if hasattr(response.output, 'message') else 'è¯­éŸ³åˆæˆå¤±è´¥'
            print(f"âŒ TTSä»»åŠ¡å¤±è´¥: {error_msg}")
            
            return jsonify({
                'status': 'failed',
                'error': error_msg,
                'task_id': task_id
            })
        else:
            # PENDING æˆ– RUNNING çŠ¶æ€
            return jsonify({
                'status': 'processing',
                'task_id': task_id
            })
            
    except Exception as error:
        print(f"âŒ Error checking TTS status: {error}")
        return jsonify({
            'error': 'Failed to check TTS status',
            'message': 'æŸ¥è¯¢TTSçŠ¶æ€æ—¶å‘ç”Ÿé”™è¯¯'
        }), 500

@app.route('/api/ai-chat', methods=['POST'])
def ai_chat():
    """AIå¯¹è¯API - ç»“åˆLLMå’ŒTTS"""
    try:
        data = request.get_json()
        
        # è·å–è¯·æ±‚å‚æ•°
        message = data.get('message', '')
        voice = data.get('voice', 'Cherry')
        language_type = data.get('language_type', 'Chinese')
        include_audio = data.get('include_audio', True)
        enable_tools = data.get('enable_tools', False)  # æ–°å¢ï¼šæ§åˆ¶æ˜¯å¦å¯ç”¨å·¥å…·
        
        if not message:
            return jsonify({
                'error': 'Missing message',
                'message': 'è¯·æä¾›å¯¹è¯æ¶ˆæ¯'
            }), 400
        
        print(f"ğŸ’¬ æ­£åœ¨å¤„ç†AIå¯¹è¯è¯·æ±‚...")
        print(f"ğŸ“ ç”¨æˆ·æ¶ˆæ¯: {message[:100]}{'...' if len(message) > 100 else ''}")
        
        # è°ƒç”¨é­”æ­ç¤¾åŒºLLMç”Ÿæˆå›å¤
        try:
            print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨é­”æ­ç¤¾åŒºLLMç”Ÿæˆå›å¤...")
            
            # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
            import requests
            
            MODELSCOPE_BASE_URL = os.getenv('MODELSCOPE_BASE_URL', 'https://api-inference.modelscope.cn/v1')
            MODELSCOPE_API_KEY = os.getenv('MODELSCOPE_API_KEY', 'xxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx')
            MODELSCOPE_MODEL = os.getenv('MODELSCOPE_MODEL', 'deepseek-ai/DeepSeek-V3.2-Exp')
            
            # æ„é€ å¯¹è¯å†å²ï¼ˆç»´æŒä¸Šä¸‹æ–‡ï¼‰
            # ä»sessionæˆ–å…¶ä»–å­˜å‚¨ä¸­è·å–å†å²å¯¹è¯ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
            
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¹–å—æ—…æ¸¸åŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä¸ºç”¨æˆ·æä¾›å…³äºæ¹–å—æ—…æ¸¸çš„ä¸“ä¸šå»ºè®®å’Œä¿¡æ¯ã€‚è¯·ç”¨å‹å¥½ã€ä¸“ä¸šçš„è¯­æ°”å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å›ç­”è¦æ±‚ï¼š1. ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼Œä¸è¦ä½¿ç”¨Markdownæˆ–å…¶ä»–æ ¼å¼ï¼›2. å›ç­”è¦ç®€æ´æ˜äº†ï¼Œçªå‡ºé‡ç‚¹ï¼›3. æä¾›å®ç”¨çš„æ—…æ¸¸å»ºè®®å’Œä¿¡æ¯ã€‚"
            
            # å¦‚æœå¯ç”¨äº†å·¥å…·ï¼Œä¿®æ”¹ç³»ç»Ÿæç¤ºè¯æˆ–æ·»åŠ å·¥å…·å®šä¹‰
            if enable_tools:
                print("ğŸ”§ å·²å¯ç”¨å·¥å…·æ”¯æŒ (MCP/Function Calling)")
                
            
            conversation_history = [
                {
                    "role": "system",
                    "content": system_prompt
                }
            ]
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            conversation_history.append({
                "role": "user",
                "content": message
            })
            
            # è°ƒç”¨é­”æ­ç¤¾åŒºAPI
            llm_response = requests.post(
                f"{MODELSCOPE_BASE_URL}/chat/completions",
                headers={
                    'Authorization': f'Bearer {MODELSCOPE_API_KEY}',
                    'Content-Type': 'application/json'
                },
                json={
                    "model": MODELSCOPE_MODEL,
                    "messages": conversation_history,
                    "stream": False
                },
                timeout=30
            )
            
            if llm_response.status_code == 200:
                llm_data = llm_response.json()
                if 'choices' in llm_data and len(llm_data['choices']) > 0:
                    ai_response = llm_data['choices'][0]['message']['content']
                else:
                    print(f"âš ï¸ LLMå“åº”æ ¼å¼å¼‚å¸¸: {llm_data}")
                    ai_response = "æ¹–å—æ˜¯ä¸€ä¸ªå……æ»¡é­…åŠ›çš„æ—…æ¸¸èƒœåœ°ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„è‡ªç„¶é£å…‰å’Œäººæ–‡æ™¯è§‚ã€‚æˆ‘ä¸ºæ‚¨æ¨èå¼ å®¶ç•Œã€å‡¤å‡°å¤åŸã€å²³é˜³æ¥¼ç­‰ç»å…¸æ™¯ç‚¹ï¼Œæ¯ä¸ªåœ°æ–¹éƒ½å€¼å¾—ç»†ç»†å“å‘³ã€‚"
            else:
                print(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å›å¤: {llm_response.status_code} - {llm_response.text}")
                ai_response = "æ¹–å—æ˜¯ä¸€ä¸ªå……æ»¡é­…åŠ›çš„æ—…æ¸¸èƒœåœ°ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„è‡ªç„¶é£å…‰å’Œäººæ–‡æ™¯è§‚ã€‚æˆ‘ä¸ºæ‚¨æ¨èå¼ å®¶ç•Œã€å‡¤å‡°å¤åŸã€å²³é˜³æ¥¼ç­‰ç»å…¸æ™¯ç‚¹ï¼Œæ¯ä¸ªåœ°æ–¹éƒ½å€¼å¾—ç»†ç»†å“å‘³ã€‚"
                
        except Exception as llm_error:
            print(f"âš ï¸ LLMè°ƒç”¨å¼‚å¸¸ï¼Œä½¿ç”¨é»˜è®¤å›å¤: {llm_error}")
            ai_response = "æ¹–å—æ˜¯ä¸€ä¸ªå……æ»¡é­…åŠ›çš„æ—…æ¸¸èƒœåœ°ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„è‡ªç„¶é£å…‰å’Œäººæ–‡æ™¯è§‚ã€‚æˆ‘ä¸ºæ‚¨æ¨èå¼ å®¶ç•Œã€å‡¤å‡°å¤åŸã€å²³é˜³æ¥¼ç­‰ç»å…¸æ™¯ç‚¹ï¼Œæ¯ä¸ªåœ°æ–¹éƒ½å€¼å¾—ç»†ç»†å“å‘³ã€‚"
        
        print(f"âœ… AIå›å¤ç”ŸæˆæˆåŠŸ")
        print(f"ğŸ“ AIå›å¤æ–‡æœ¬é•¿åº¦: {len(ai_response)} å­—ç¬¦")
        print(f"ğŸ“ AIå›å¤å†…å®¹: {ai_response[:200]}{'...' if len(ai_response) > 200 else ''}")
        
        result = {
            'user_message': message,
            'ai_response': ai_response,
            'voice': voice,
            'language_type': language_type
        }
        
        # å¦‚æœéœ€è¦éŸ³é¢‘ï¼Œè°ƒç”¨TTS
        if include_audio and os.getenv('DASHSCOPE_API_KEY'):
            try:
                print(f"ğŸ—£ï¸ æ­£åœ¨ä¸ºAIå›å¤ç”Ÿæˆè¯­éŸ³...")
                
                # æ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼Œå¦‚æœè¶…è¿‡600å­—èŠ‚åˆ™è¿›è¡Œåˆ†æ®µå¤„ç†
                max_length = 600
                text_bytes = len(ai_response.encode('utf-8'))
                print(f"ğŸ“ æ–‡æœ¬å­—èŠ‚é•¿åº¦: {text_bytes} (å­—ç¬¦é•¿åº¦: {len(ai_response)})")
                
                if text_bytes > max_length:
                    print(f"âš ï¸ æ–‡æœ¬å­—èŠ‚é•¿åº¦è¶…è¿‡é™åˆ¶ ({text_bytes} > {max_length})ï¼Œæ­£åœ¨è¿›è¡Œåˆ†æ®µå¤„ç†...")
                    
                    # æ™ºèƒ½åˆ†æ®µï¼šæŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ‡å‰²ï¼Œå°½é‡ä¿æŒè¯­ä¹‰å®Œæ•´
                    import re
                    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', ai_response)
                    segments = []
                    current_segment = ""
                    
                    for sentence in sentences:
                        sentence = sentence.strip()
                        if not sentence:
                            continue
                            
                        sentence_with_punct = sentence + "ã€‚"  # é»˜è®¤ä½¿ç”¨å¥å·
                        
                        # è®¡ç®—å½“å‰æ®µå’Œæ–°å¥å­çš„å­—èŠ‚é•¿åº¦
                        current_bytes = len(current_segment.encode('utf-8'))
                        sentence_bytes = len(sentence_with_punct.encode('utf-8'))
                        
                        # å¦‚æœå½“å‰æ®µåŠ ä¸Šæ–°å¥å­ä¸è¶…è¿‡é™åˆ¶ï¼Œåˆ™æ·»åŠ 
                        if current_bytes + sentence_bytes <= max_length:
                            current_segment += sentence_with_punct
                        else:
                            # å¦‚æœå½“å‰æ®µä¸ä¸ºç©ºï¼Œåˆ™ä¿å­˜
                            if current_segment.strip():
                                segments.append(current_segment.strip())
                            
                            # å¦‚æœæ–°å¥å­æœ¬èº«ä¸è¶…è¿‡é™åˆ¶ï¼Œåˆ™ä½œä¸ºæ–°æ®µ
                            if sentence_bytes <= max_length:
                                current_segment = sentence_with_punct
                            else:
                                # å¦‚æœå¥å­æœ¬èº«è¶…è¿‡é™åˆ¶ï¼Œåˆ™æŒ‰å­—èŠ‚å¼ºåˆ¶æˆªæ–­
                                # é€æ­¥æˆªæ–­ç›´åˆ°å­—èŠ‚é•¿åº¦ç¬¦åˆè¦æ±‚
                                truncated = sentence
                                while len(truncated.encode('utf-8')) > max_length - 3:  # ç•™3å­—èŠ‚ç»™"..."
                                    truncated = truncated[:-1]
                                truncated += "..."
                                segments.append(truncated)
                                current_segment = ""
                    
                    # æ·»åŠ æœ€åä¸€æ®µ
                    if current_segment.strip():
                        segments.append(current_segment.strip())
                    
                    # éªŒè¯æ¯æ®µçš„å­—èŠ‚é•¿åº¦
                    for i, segment in enumerate(segments):
                        segment_bytes = len(segment.encode('utf-8'))
                        print(f"ğŸ“Š æ®µ {i+1}: {segment_bytes} å­—èŠ‚, {len(segment)} å­—ç¬¦")
                        if segment_bytes > max_length:
                            print(f"âš ï¸ æ®µ {i+1} ä»ç„¶è¶…è¿‡é™åˆ¶ï¼Œè¿›è¡Œå¼ºåˆ¶æˆªæ–­")
                            # å¼ºåˆ¶æˆªæ–­
                            while len(segment.encode('utf-8')) > max_length:
                                segment = segment[:-1]
                            segments[i] = segment
                    
                    print(f"âœ‚ï¸ æ–‡æœ¬å·²åˆ†æ®µï¼Œå…± {len(segments)} æ®µ")
                    
                    # ä¸ºæ¯æ®µç”ŸæˆTTSéŸ³é¢‘
                    audio_urls = []
                    tts_model = os.getenv('DASHSCOPE_TTS_MODEL', 'qwen3-tts-flash')
                    for i, segment in enumerate(segments):
                        print(f"ğŸ—£ï¸ æ­£åœ¨ç”Ÿæˆç¬¬ {i+1} æ®µéŸ³é¢‘ (é•¿åº¦: {len(segment)})...")
                        
                        try:
                            tts_response = dashscope.MultiModalConversation.call(
                                model=tts_model,
                                api_key=os.getenv('DASHSCOPE_API_KEY'),
                                text=segment,
                                voice=voice,
                                language_type=language_type,
                                stream=False
                            )
                            
                            if tts_response and hasattr(tts_response, 'output') and tts_response.output:
                                if hasattr(tts_response.output, 'audio') and tts_response.output.audio:
                                    audio_info = tts_response.output.audio
                                    if hasattr(audio_info, 'url') and audio_info.url:
                                        audio_urls.append(audio_info.url)
                                        print(f"âœ… ç¬¬ {i+1} æ®µéŸ³é¢‘ç”ŸæˆæˆåŠŸ: {audio_info.url}")
                                    else:
                                        print(f"âŒ ç¬¬ {i+1} æ®µéŸ³é¢‘URLè·å–å¤±è´¥: {audio_info}")
                                else:
                                    print(f"âŒ ç¬¬ {i+1} æ®µéŸ³é¢‘ä¿¡æ¯æ ¼å¼å¼‚å¸¸: {tts_response.output}")
                            else:
                                print(f"âŒ ç¬¬ {i+1} æ®µTTSè°ƒç”¨å¤±è´¥: {tts_response}")
                                
                        except Exception as segment_error:
                            print(f"âŒ ç¬¬ {i+1} æ®µéŸ³é¢‘ç”Ÿæˆå¼‚å¸¸: {segment_error}")
                    
                    if audio_urls:
                        result['audio_urls'] = audio_urls
                        print(f"âœ… å…±ç”Ÿæˆ {len(audio_urls)} æ®µéŸ³é¢‘")
                    else:
                        result['audio_error'] = 'æ‰€æœ‰åˆ†æ®µéŸ³é¢‘ç”Ÿæˆå‡å¤±è´¥'
                else:
                    # æ–‡æœ¬é•¿åº¦æœªè¶…è¿‡é™åˆ¶ï¼Œç›´æ¥ç”ŸæˆéŸ³é¢‘
                    tts_model = os.getenv('DASHSCOPE_TTS_MODEL', 'qwen3-tts-flash')
                    tts_response = dashscope.MultiModalConversation.call(
                        model=tts_model,
                        api_key=os.getenv('DASHSCOPE_API_KEY'),
                        text=ai_response,
                        voice=voice,
                        language_type=language_type,
                        stream=False
                    )
                    
                    print(f"ğŸ“‹ TTSå“åº”: {tts_response}")
                    
                    if tts_response and hasattr(tts_response, 'output') and tts_response.output:
                        # æ£€æŸ¥æ˜¯å¦æœ‰ç›´æ¥çš„éŸ³é¢‘URL
                        if hasattr(tts_response.output, 'audio') and tts_response.output.audio:
                            audio_info = tts_response.output.audio
                            if hasattr(audio_info, 'url') and audio_info.url:
                                # ç›´æ¥è¿”å›éŸ³é¢‘URL
                                result['audio_url'] = audio_info.url
                                print(f"âœ… TTSéŸ³é¢‘ç”ŸæˆæˆåŠŸï¼ŒéŸ³é¢‘URL: {audio_info.url}")
                            elif hasattr(audio_info, 'id') and audio_info.id:
                                # è¿”å›éŸ³é¢‘IDç”¨äºåç»­æŸ¥è¯¢
                                result['audio_task_id'] = audio_info.id
                                print(f"âœ… TTSä»»åŠ¡åˆ›å»ºæˆåŠŸ (éŸ³é¢‘ID: {audio_info.id})")
                            else:
                                print(f"âŒ TTSéŸ³é¢‘ä¿¡æ¯æ ¼å¼å¼‚å¸¸: {audio_info}")
                                result['audio_error'] = 'TTSéŸ³é¢‘ä¿¡æ¯æ ¼å¼å¼‚å¸¸'
                        elif hasattr(tts_response.output, 'task_id'):
                            # å…¼å®¹ä»»åŠ¡IDæ ¼å¼
                            result['audio_task_id'] = tts_response.output.task_id
                            print(f"âœ… TTSä»»åŠ¡åˆ›å»ºæˆåŠŸ (ä»»åŠ¡ID: {tts_response.output.task_id})")
                        else:
                            print(f"âŒ TTSå“åº”æ ¼å¼å¼‚å¸¸: {tts_response.output}")
                            result['audio_error'] = 'TTS APIå“åº”æ ¼å¼å¼‚å¸¸'
                    else:
                        print(f"âŒ TTSå“åº”æ ¼å¼å¼‚å¸¸: {tts_response}")
                        result['audio_error'] = 'TTS APIå“åº”æ ¼å¼å¼‚å¸¸'
                
            except Exception as tts_error:
                print(f'âš ï¸ TTSç”Ÿæˆå¤±è´¥ï¼Œä½†æ–‡æœ¬å›å¤æ­£å¸¸: {tts_error}')
                result['audio_error'] = str(tts_error)
        elif include_audio and not os.getenv('DASHSCOPE_API_KEY'):
            result['audio_error'] = 'TTSåŠŸèƒ½ä¸å¯ç”¨ï¼Œæœªé…ç½®DashScope APIå¯†é’¥'
        
        return jsonify(result)
        
    except Exception as error:
        print(f"âŒ Error in AI chat: {error}")
        return jsonify({
            'error': 'Failed to process AI chat',
            'message': 'å¤„ç†AIå¯¹è¯æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•'
        }), 500

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))  # é»˜è®¤ç«¯å£5000
    print(f"ğŸš€ Flask TTS Server is running on port {port}")
    print(f"ğŸ“ TTS API: http://localhost:{port}")
    
    app.run(host='0.0.0.0', port=port, debug=True)
