import os
import json
from flask import Flask, request, jsonify
from flask_cors import CORS
import dashscope
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain_mcp_adapters.client import MultiServerMCPClient

from langchain.agents.middleware import AgentMiddleware
from langchain.tools.tool_node import ToolCallRequest
from langchain.messages import ToolMessage
from langgraph.types import Command
from typing import Callable, Awaitable, Dict, List

class ToolErrorHandlerMiddleware(AgentMiddleware):
    """å¤„ç†å·¥å…·é”™è¯¯ï¼Œå¹¶è®©æ¨¡å‹é‡æ–°å°è¯•"""
    
    def wrap_tool_call(
        self,
        request: ToolCallRequest,
        handler: Callable[[ToolCallRequest], ToolMessage | Command],
    ) -> ToolMessage | Command:
        """åœ¨å·¥å…·è°ƒç”¨å‘¨å›´åŒ…è£…é”™è¯¯å¤„ç†"""
        try:
            print(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {request.tool_call['name']}")
            print(f"ğŸ“ å‚æ•°: {request.tool_call['args']}")
            
            result = handler(request)
            print(f"âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ")
            return result
            
        except Exception as e:
            error_msg = (
                f"å·¥å…· '{request.tool_call['name']}' æ‰§è¡Œå¤±è´¥ã€‚\n"
                f"é”™è¯¯: {str(e)}\n"
                f"è¯·æ£€æŸ¥å‚æ•°å¹¶é‡æ–°å°è¯•"
            )
            print(f"âŒ å·¥å…·é”™è¯¯: {error_msg}")
            
            # è¿”å›ToolMessageï¼Œè®©æ¨¡å‹ç»§ç»­å¤„ç†
            return ToolMessage(
                content=error_msg,
                tool_call_id=request.tool_call["id"],
                name=request.tool_call["name"]
            )

    async def awrap_tool_call(
        self,
        request: ToolCallRequest,
        handler: Callable[[ToolCallRequest], Awaitable[ToolMessage | Command]],
    ) -> ToolMessage | Command:
        """å¼‚æ­¥åŒ…è£…å·¥å…·è°ƒç”¨ï¼Œç¡®ä¿åœ¨ainvokeåœºæ™¯æ­£å¸¸è¿è¡Œ"""
        try:
            print(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {request.tool_call['name']}")
            print(f"ğŸ“ å‚æ•°: {request.tool_call['args']}")

            result = await handler(request)
            print(f"âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ")
            return result

        except Exception as e:
            error_msg = (
                f"å·¥å…· '{request.tool_call['name']}' æ‰§è¡Œå¤±è´¥ã€‚\n"
                f"é”™è¯¯: {str(e)}\n"
                f"è¯·æ£€æŸ¥å‚æ•°å¹¶é‡æ–°å°è¯•"
            )
            print(f"âŒ å·¥å…·é”™è¯¯: {error_msg}")

            return ToolMessage(
                content=error_msg,
                tool_call_id=request.tool_call["id"],
                name=request.tool_call["name"]
            )

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®DashScope API URL
dashscope.base_http_api_url = 'https://dashscope.aliyuncs.com/api/v1'

app = Flask(__name__)

# åˆå§‹åŒ–MCPå®¢æˆ·ç«¯ï¼ˆåœ¨åº”ç”¨å¯åŠ¨æ—¶ï¼‰
mcp_client = None

# ç®€æ˜“ä¼šè¯å­˜å‚¨ï¼ˆå†…å­˜çº§ï¼Œé‡å¯å³å¤±ï¼‰ï¼ŒæŒ‰conversation_idåˆ†ç»„
conversation_sessions: Dict[str, List[dict]] = {}
MAX_HISTORY_MESSAGES = int(os.getenv('AI_CHAT_HISTORY_LIMIT', '12'))  # æ€»æ¶ˆæ¯ä¸Šé™


def get_conversation_history(conversation_id: str) -> List[dict]:
    """è·å–æŒ‡å®šä¼šè¯çš„å†å²æ¶ˆæ¯åˆ—è¡¨"""
    return conversation_sessions.setdefault(conversation_id, [])


def trim_conversation_history(history: List[dict]) -> None:
    """é™åˆ¶å†å²é•¿åº¦ï¼Œé¿å…æ— é™å¢é•¿"""
    if len(history) > MAX_HISTORY_MESSAGES:
        # ä»…ä¿ç•™æœ€è¿‘çš„è‹¥å¹²æ¡æ¶ˆæ¯
        history[:] = history[-MAX_HISTORY_MESSAGES:]

@app.before_request
async def init_mcp():
    global mcp_client
    if mcp_client is None:
        mcp_client = MultiServerMCPClient({
            "12306-mcp": {
                "transport": "stdio",
                "command": "npx",
                "args": ["-y", "12306-mcp"],
            },
            "bing-cn-mcp-server": {
                "transport": "sse",
                "url": "https://mcp.api-inference.modelscope.net/23494d15514349/sse",  # è¿œç¨‹MCPæœåŠ¡å™¨
            }
        })


CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({'status': 'ok'})

@app.route('/api/tts', methods=['POST'])
def text_to_speech():
    """æ–‡å­—è½¬è¯­éŸ³API"""
    try:
        data = request.get_json()
        
        # è·å–è¯·æ±‚å‚æ•°
        text = data.get('text', '')
        voice = data.get('voice', 'Cherry')
        language_type = data.get('language_type', 'Chinese')
        
        if not text:
            return jsonify({
                'error': 'Missing text',
                'message': 'è¯·æä¾›è¦è½¬æ¢çš„æ–‡æœ¬å†…å®¹'
            }), 400
        
        # æ£€æŸ¥API Key
        api_key = os.getenv('DASHSCOPE_API_KEY')
        tts_model = os.getenv('DASHSCOPE_TTS_MODEL', 'qwen3-tts-flash')
        if not api_key:
            return jsonify({
                'error': 'TTSåŠŸèƒ½ä¸å¯ç”¨',
                'message': 'ç³»ç»Ÿç®¡ç†å‘˜éœ€è¦é…ç½®DashScope APIå¯†é’¥æ‰èƒ½ä½¿ç”¨è¯­éŸ³åˆæˆåŠŸèƒ½'
            }), 500
        
        print(f"ğŸ—£ï¸ æ­£åœ¨è°ƒç”¨é€šä¹‰åƒé—®TTS API...")
        print(f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        print(f"ğŸ¤ éŸ³è‰²: {voice}")
        print(f"ğŸŒ è¯­è¨€: {language_type}")
        
        # è°ƒç”¨DashScope TTS API
        response = dashscope.MultiModalConversation.call(
            model=tts_model,
            api_key=api_key,
            text=text,
            voice=voice,
            language_type=language_type,
            stream=False
        )
        
        print(f"âœ… TTSä»»åŠ¡åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“‹ å“åº”å†…å®¹: {response}")
        
        return jsonify({
            'taskId': response.output.task_id,
            'model': tts_model,
            'voice': voice,
            'language_type': language_type,
            'text_length': len(text)
        })
        
    except Exception as error:
        print(f"âŒ Error calling TTS API: {error}")
        
        error_message = 'è¯­éŸ³åˆæˆæ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•'
        
        # å¤„ç†ç‰¹å®šé”™è¯¯ç±»å‹
        if hasattr(error, 'code'):
            if error.code == 'InvalidParameter':
                error_message = 'è¯·æ±‚å‚æ•°æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ–‡æœ¬å†…å®¹å’ŒéŸ³è‰²è®¾ç½®'
            elif error.code == 'InvalidApiKey':
                error_message = 'APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®'
            elif error.code == 'QuotaExceeded':
                error_message = 'TTSé…é¢å·²ç”¨å®Œï¼Œè¯·ç¨åå†è¯•'
            elif error.code == 'TextTooLong':
                error_message = 'æ–‡æœ¬è¿‡é•¿ï¼Œè¯·åˆ†æ®µå¤„ç†'
            else:
                error_message = error.message or error_message
        else:
            error_message = str(error) or error_message
        
        return jsonify({
            'error': 'Failed to synthesize speech',
            'message': error_message,
            'code': getattr(error, 'code', None)
        }), 500

@app.route('/api/tts/audio/<task_id>', methods=['GET'])
def get_tts_audio(task_id):
    """è·å–TTSéŸ³é¢‘æ–‡ä»¶"""
    try:
        if not task_id:
            return jsonify({
                'error': 'Missing taskId',
                'message': 'è¯·æä¾›ä»»åŠ¡ID'
            }), 400
        
        print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢TTSä»»åŠ¡çŠ¶æ€: {task_id}")
        
        # æ£€æŸ¥API Key
        api_key = os.getenv('DASHSCOPE_API_KEY')
        tts_model = os.getenv('DASHSCOPE_TTS_MODEL', 'qwen3-tts-flash')
        if not api_key:
            return jsonify({
                'error': 'TTSåŠŸèƒ½ä¸å¯ç”¨',
                'message': 'ç³»ç»Ÿç®¡ç†å‘˜éœ€è¦é…ç½®DashScope APIå¯†é’¥æ‰èƒ½ä½¿ç”¨è¯­éŸ³åˆæˆåŠŸèƒ½'
            }), 500
        
        # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
        response = dashscope.MultiModalConversation.call(
            model=tts_model,
            api_key=api_key,
            input={'task_id': task_id}
        )
        
        if not response or not response.output:
            raise Exception('TTSçŠ¶æ€æŸ¥è¯¢å¤±è´¥')
        
        task_status = response.output.task_status
        
        if task_status == 'SUCCEED':
            audio_url = response.output.audio_url
            print(f"âœ… TTSä»»åŠ¡å®Œæˆï¼ŒéŸ³é¢‘URL: {audio_url}")
            
            return jsonify({
                'status': 'completed',
                'audio_url': audio_url,
                'task_id': task_id
            })
        elif task_status == 'FAILED':
            error_msg = response.output.message if hasattr(response.output, 'message') else 'è¯­éŸ³åˆæˆå¤±è´¥'
            print(f"âŒ TTSä»»åŠ¡å¤±è´¥: {error_msg}")
            
            return jsonify({
                'status': 'failed',
                'error': error_msg,
                'task_id': task_id
            })
        else:
            # PENDING æˆ– RUNNING çŠ¶æ€
            return jsonify({
                'status': 'processing',
                'task_id': task_id
            })
            
    except Exception as error:
        print(f"âŒ Error checking TTS status: {error}")
        return jsonify({
            'error': 'Failed to check TTS status',
            'message': 'æŸ¥è¯¢TTSçŠ¶æ€æ—¶å‘ç”Ÿé”™è¯¯'
        }), 500

@app.route('/api/ai-chat', methods=['POST'])
async def ai_chat():
    """AIå¯¹è¯API - ç»“åˆLLMå’ŒTTS"""
    try:
        data = request.get_json()
        
        # è·å–è¯·æ±‚å‚æ•°
        message = data.get('message', '')
        voice = data.get('voice', 'Cherry')
        language_type = data.get('language_type', 'Chinese')
        include_audio = data.get('include_audio', True)
        enable_tools = data.get('enable_tools', False)  # æ–°å¢ï¼šæ§åˆ¶æ˜¯å¦å¯ç”¨å·¥å…·
        conversation_id = data.get('conversation_id', 'default')
        reset_history = data.get('reset_history', False)
        history: List[dict] | None = None
        
        if not message:
            return jsonify({
                'error': 'Missing message',
                'message': 'è¯·æä¾›å¯¹è¯æ¶ˆæ¯'
            }), 400

        if enable_tools:
            history = get_conversation_history(conversation_id)
            if reset_history:
                history.clear()
        
        print(f"ğŸ’¬ æ­£åœ¨å¤„ç†AIå¯¹è¯è¯·æ±‚...")
        print(f"ğŸ“ ç”¨æˆ·æ¶ˆæ¯: {message[:100]}{'...' if len(message) > 100 else ''}")
        
        # è°ƒç”¨é­”æ­ç¤¾åŒºLLMç”Ÿæˆå›å¤
        try:
            print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨é­”æ­ç¤¾åŒºLLMç”Ÿæˆå›å¤...")
            
            # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®            
            MODELSCOPE_BASE_URL = os.getenv('MODELSCOPE_BASE_URL', 'https://api-inference.modelscope.cn/v1')
            MODELSCOPE_API_KEY = os.getenv('MODELSCOPE_API_KEY', 'xxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx')
            MODELSCOPE_MODEL = os.getenv('MODELSCOPE_MODEL', 'deepseek-ai/DeepSeek-V3.2-Exp')

            llm = ChatOpenAI(
                model=MODELSCOPE_MODEL,
                api_key=MODELSCOPE_API_KEY,
                base_url=MODELSCOPE_BASE_URL)
            
            # æ„é€ å¯¹è¯å†å²ï¼ˆç»´æŒä¸Šä¸‹æ–‡ï¼‰
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…æ¸¸åŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä¸ºç”¨æˆ·æä¾›å…³äºæ¹–å—æ—…æ¸¸çš„ä¸“ä¸šå»ºè®®å’Œä¿¡æ¯ã€‚è¯·ç”¨å‹å¥½ã€ä¸“ä¸šçš„è¯­æ°”å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å›ç­”è¦æ±‚ï¼š1. ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼Œä¸è¦ä½¿ç”¨Markdownæˆ–å…¶ä»–æ ¼å¼ï¼›2. å›ç­”è¦ç®€æ´æ˜äº†ï¼Œçªå‡ºé‡ç‚¹ï¼›3. æä¾›å®ç”¨çš„æ—…æ¸¸å»ºè®®å’Œä¿¡æ¯ã€‚"

            conversation_history = [
                {
                    "role": "system",
                    "content": system_prompt
                }
            ]

            if history:
                conversation_history.extend(history)

            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            conversation_history.append({
                "role": "user",
                "content": message
            })
            
            # å¦‚æœå¯ç”¨äº†å·¥å…·ï¼Œä¿®æ”¹ç³»ç»Ÿæç¤ºè¯æˆ–æ·»åŠ å·¥å…·å®šä¹‰
            if enable_tools:
                print("ğŸ”§ å·²å¯ç”¨å·¥å…·æ”¯æŒ (MCP/Function Calling)")
                # è·å–MCPå·¥å…·
                tools = await mcp_client.get_tools()
                print(f"ğŸ”§ å¯ç”¨å·¥å…·æ•°é‡: {len(tools)}")
                print(f"ğŸ”§ å·¥å…·åˆ—è¡¨: {[tool.name for tool in tools]}")
                agent = create_agent(
                    model=llm,
                    tools=tools,
                    system_prompt=system_prompt,
                    middleware=[
                        ToolErrorHandlerMiddleware()
                    ],  
                )
                 # è°ƒç”¨Agentè·å–æœ€ç»ˆå›ç­”
                response = await agent.ainvoke({
                    "messages": conversation_history
                })
                print(f"âœ… LLMå›å¤ç”ŸæˆæˆåŠŸ (å·¥å…·æ¨¡å¼)")
                print(f"ğŸ“‹ LLMå®Œæ•´å“åº”: {response}")

                # æå–æœ€ç»ˆæ¶ˆæ¯
                final_message = response["messages"][-1]
                ai_response = final_message.content                

            else:
                agent = create_agent(
                    model=llm,
                    system_prompt=system_prompt,
                )

                # Run the agent
                result = agent.invoke(
                    {"messages": conversation_history}
                )
                print(f"âœ… LLMå›å¤ç”ŸæˆæˆåŠŸ (æ— å·¥å…·æ¨¡å¼)")
                # è·å–æœ€ç»ˆå›ç­”ï¼ˆæœ€åä¸€æ¡æ¶ˆæ¯ï¼‰
                final_message = result["messages"][-1]
                ai_response = final_message.content

            # å¦‚æœå·¥å…·æ¨¡å¼æœªç”Ÿæˆæœ‰æ•ˆå›å¤ï¼Œå›é€€åˆ°æ— å·¥å…·æ¨¡å¼
            if not ai_response or ai_response.strip() == "":
                agent = create_agent(
                    model=llm,
                    system_prompt=system_prompt,
                )

                # Run the agent
                result = agent.invoke(
                    {"messages": conversation_history}
                )
                print(f"âœ… LLMå›å¤ç”ŸæˆæˆåŠŸ (æ— å·¥å…·æ¨¡å¼)")
                # è·å–æœ€ç»ˆå›ç­”ï¼ˆæœ€åä¸€æ¡æ¶ˆæ¯ï¼‰
                final_message = result["messages"][-1]
                ai_response = final_message.content
                                
                
        except Exception as llm_error:
            print(f"âš ï¸ LLMè°ƒç”¨å¼‚å¸¸ï¼Œä½¿ç”¨é»˜è®¤å›å¤: {llm_error}")
            ai_response = "æ¹–å—æ˜¯ä¸€ä¸ªå……æ»¡é­…åŠ›çš„æ—…æ¸¸èƒœåœ°ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„è‡ªç„¶é£å…‰å’Œäººæ–‡æ™¯è§‚ã€‚æˆ‘ä¸ºæ‚¨æ¨èå¼ å®¶ç•Œã€å‡¤å‡°å¤åŸã€å²³é˜³æ¥¼ç­‰ç»å…¸æ™¯ç‚¹ï¼Œæ¯ä¸ªåœ°æ–¹éƒ½å€¼å¾—ç»†ç»†å“å‘³ã€‚"

        # å°†æœ¬è½®å¯¹è¯å†™å…¥å†å²ï¼ˆä»…å·¥å…·æ¨¡å¼éœ€è¦ä¸Šä¸‹æ–‡ï¼‰
        if history is not None:
            history.extend([
                {
                    "role": "user",
                    "content": message
                },
                {
                    "role": "assistant",
                    "content": ai_response
                }
            ])
            trim_conversation_history(history)
        
        print(f"âœ… AIå›å¤ç”ŸæˆæˆåŠŸ")
        print(f"ğŸ“ AIå›å¤æ–‡æœ¬é•¿åº¦: {len(ai_response)} å­—ç¬¦")
        print(f"ğŸ“ AIå›å¤å†…å®¹: {ai_response[:200]}{'...' if len(ai_response) > 200 else ''}")
        
        result = {
            'user_message': message,
            'ai_response': ai_response,
            'voice': voice,
            'language_type': language_type
        }
        
        # å¦‚æœéœ€è¦éŸ³é¢‘ï¼Œè°ƒç”¨TTS
        if include_audio and os.getenv('DASHSCOPE_API_KEY'):
            try:
                print(f"ğŸ—£ï¸ æ­£åœ¨ä¸ºAIå›å¤ç”Ÿæˆè¯­éŸ³...")
                
                # æ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼Œå¦‚æœè¶…è¿‡600å­—èŠ‚åˆ™è¿›è¡Œåˆ†æ®µå¤„ç†
                max_length = 600
                text_bytes = len(ai_response.encode('utf-8'))
                print(f"ğŸ“ æ–‡æœ¬å­—èŠ‚é•¿åº¦: {text_bytes} (å­—ç¬¦é•¿åº¦: {len(ai_response)})")
                
                if text_bytes > max_length:
                    print(f"âš ï¸ æ–‡æœ¬å­—èŠ‚é•¿åº¦è¶…è¿‡é™åˆ¶ ({text_bytes} > {max_length})ï¼Œæ­£åœ¨è¿›è¡Œåˆ†æ®µå¤„ç†...")
                    
                    # æ™ºèƒ½åˆ†æ®µï¼šæŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ‡å‰²ï¼Œå°½é‡ä¿æŒè¯­ä¹‰å®Œæ•´
                    import re
                    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', ai_response)
                    segments = []
                    current_segment = ""
                    
                    for sentence in sentences:
                        sentence = sentence.strip()
                        if not sentence:
                            continue
                            
                        sentence_with_punct = sentence + "ã€‚"  # é»˜è®¤ä½¿ç”¨å¥å·
                        
                        # è®¡ç®—å½“å‰æ®µå’Œæ–°å¥å­çš„å­—èŠ‚é•¿åº¦
                        current_bytes = len(current_segment.encode('utf-8'))
                        sentence_bytes = len(sentence_with_punct.encode('utf-8'))
                        
                        # å¦‚æœå½“å‰æ®µåŠ ä¸Šæ–°å¥å­ä¸è¶…è¿‡é™åˆ¶ï¼Œåˆ™æ·»åŠ 
                        if current_bytes + sentence_bytes <= max_length:
                            current_segment += sentence_with_punct
                        else:
                            # å¦‚æœå½“å‰æ®µä¸ä¸ºç©ºï¼Œåˆ™ä¿å­˜
                            if current_segment.strip():
                                segments.append(current_segment.strip())
                            
                            # å¦‚æœæ–°å¥å­æœ¬èº«ä¸è¶…è¿‡é™åˆ¶ï¼Œåˆ™ä½œä¸ºæ–°æ®µ
                            if sentence_bytes <= max_length:
                                current_segment = sentence_with_punct
                            else:
                                # å¦‚æœå¥å­æœ¬èº«è¶…è¿‡é™åˆ¶ï¼Œåˆ™æŒ‰å­—èŠ‚å¼ºåˆ¶æˆªæ–­
                                # é€æ­¥æˆªæ–­ç›´åˆ°å­—èŠ‚é•¿åº¦ç¬¦åˆè¦æ±‚
                                truncated = sentence
                                while len(truncated.encode('utf-8')) > max_length - 3:  # ç•™3å­—èŠ‚ç»™"..."
                                    truncated = truncated[:-1]
                                truncated += "..."
                                segments.append(truncated)
                                current_segment = ""
                    
                    # æ·»åŠ æœ€åä¸€æ®µ
                    if current_segment.strip():
                        segments.append(current_segment.strip())
                    
                    # éªŒè¯æ¯æ®µçš„å­—èŠ‚é•¿åº¦
                    for i, segment in enumerate(segments):
                        segment_bytes = len(segment.encode('utf-8'))
                        print(f"ğŸ“Š æ®µ {i+1}: {segment_bytes} å­—èŠ‚, {len(segment)} å­—ç¬¦")
                        if segment_bytes > max_length:
                            print(f"âš ï¸ æ®µ {i+1} ä»ç„¶è¶…è¿‡é™åˆ¶ï¼Œè¿›è¡Œå¼ºåˆ¶æˆªæ–­")
                            # å¼ºåˆ¶æˆªæ–­
                            while len(segment.encode('utf-8')) > max_length:
                                segment = segment[:-1]
                            segments[i] = segment
                    
                    print(f"âœ‚ï¸ æ–‡æœ¬å·²åˆ†æ®µï¼Œå…± {len(segments)} æ®µ")
                    
                    # ä¸ºæ¯æ®µç”ŸæˆTTSéŸ³é¢‘
                    audio_urls = []
                    tts_model = os.getenv('DASHSCOPE_TTS_MODEL', 'qwen3-tts-flash')
                    for i, segment in enumerate(segments):
                        print(f"ğŸ—£ï¸ æ­£åœ¨ç”Ÿæˆç¬¬ {i+1} æ®µéŸ³é¢‘ (é•¿åº¦: {len(segment)})...")
                        
                        try:
                            tts_response = dashscope.MultiModalConversation.call(
                                model=tts_model,
                                api_key=os.getenv('DASHSCOPE_API_KEY'),
                                text=segment,
                                voice=voice,
                                language_type=language_type,
                                stream=False
                            )
                            
                            if tts_response and hasattr(tts_response, 'output') and tts_response.output:
                                if hasattr(tts_response.output, 'audio') and tts_response.output.audio:
                                    audio_info = tts_response.output.audio
                                    if hasattr(audio_info, 'url') and audio_info.url:
                                        audio_urls.append(audio_info.url)
                                        print(f"âœ… ç¬¬ {i+1} æ®µéŸ³é¢‘ç”ŸæˆæˆåŠŸ: {audio_info.url}")
                                    else:
                                        print(f"âŒ ç¬¬ {i+1} æ®µéŸ³é¢‘URLè·å–å¤±è´¥: {audio_info}")
                                else:
                                    print(f"âŒ ç¬¬ {i+1} æ®µéŸ³é¢‘ä¿¡æ¯æ ¼å¼å¼‚å¸¸: {tts_response.output}")
                            else:
                                print(f"âŒ ç¬¬ {i+1} æ®µTTSè°ƒç”¨å¤±è´¥: {tts_response}")
                                
                        except Exception as segment_error:
                            print(f"âŒ ç¬¬ {i+1} æ®µéŸ³é¢‘ç”Ÿæˆå¼‚å¸¸: {segment_error}")
                    
                    if audio_urls:
                        result['audio_urls'] = audio_urls
                        print(f"âœ… å…±ç”Ÿæˆ {len(audio_urls)} æ®µéŸ³é¢‘")
                    else:
                        result['audio_error'] = 'æ‰€æœ‰åˆ†æ®µéŸ³é¢‘ç”Ÿæˆå‡å¤±è´¥'
                else:
                    # æ–‡æœ¬é•¿åº¦æœªè¶…è¿‡é™åˆ¶ï¼Œç›´æ¥ç”ŸæˆéŸ³é¢‘
                    tts_model = os.getenv('DASHSCOPE_TTS_MODEL', 'qwen3-tts-flash')
                    tts_response = dashscope.MultiModalConversation.call(
                        model=tts_model,
                        api_key=os.getenv('DASHSCOPE_API_KEY'),
                        text=ai_response,
                        voice=voice,
                        language_type=language_type,
                        stream=False
                    )
                    
                    print(f"ğŸ“‹ TTSå“åº”: {tts_response}")
                    
                    if tts_response and hasattr(tts_response, 'output') and tts_response.output:
                        # æ£€æŸ¥æ˜¯å¦æœ‰ç›´æ¥çš„éŸ³é¢‘URL
                        if hasattr(tts_response.output, 'audio') and tts_response.output.audio:
                            audio_info = tts_response.output.audio
                            if hasattr(audio_info, 'url') and audio_info.url:
                                # ç›´æ¥è¿”å›éŸ³é¢‘URL
                                result['audio_url'] = audio_info.url
                                print(f"âœ… TTSéŸ³é¢‘ç”ŸæˆæˆåŠŸï¼ŒéŸ³é¢‘URL: {audio_info.url}")
                            elif hasattr(audio_info, 'id') and audio_info.id:
                                # è¿”å›éŸ³é¢‘IDç”¨äºåç»­æŸ¥è¯¢
                                result['audio_task_id'] = audio_info.id
                                print(f"âœ… TTSä»»åŠ¡åˆ›å»ºæˆåŠŸ (éŸ³é¢‘ID: {audio_info.id})")
                            else:
                                print(f"âŒ TTSéŸ³é¢‘ä¿¡æ¯æ ¼å¼å¼‚å¸¸: {audio_info}")
                                result['audio_error'] = 'TTSéŸ³é¢‘ä¿¡æ¯æ ¼å¼å¼‚å¸¸'
                        elif hasattr(tts_response.output, 'task_id'):
                            # å…¼å®¹ä»»åŠ¡IDæ ¼å¼
                            result['audio_task_id'] = tts_response.output.task_id
                            print(f"âœ… TTSä»»åŠ¡åˆ›å»ºæˆåŠŸ (ä»»åŠ¡ID: {tts_response.output.task_id})")
                        else:
                            print(f"âŒ TTSå“åº”æ ¼å¼å¼‚å¸¸: {tts_response.output}")
                            result['audio_error'] = 'TTS APIå“åº”æ ¼å¼å¼‚å¸¸'
                    else:
                        print(f"âŒ TTSå“åº”æ ¼å¼å¼‚å¸¸: {tts_response}")
                        result['audio_error'] = 'TTS APIå“åº”æ ¼å¼å¼‚å¸¸'
                
            except Exception as tts_error:
                print(f'âš ï¸ TTSç”Ÿæˆå¤±è´¥ï¼Œä½†æ–‡æœ¬å›å¤æ­£å¸¸: {tts_error}')
                result['audio_error'] = str(tts_error)
        elif include_audio and not os.getenv('DASHSCOPE_API_KEY'):
            result['audio_error'] = 'TTSåŠŸèƒ½ä¸å¯ç”¨ï¼Œæœªé…ç½®DashScope APIå¯†é’¥'
        
        return jsonify(result)
        
    except Exception as error:
        print(f"âŒ Error in AI chat: {error}")
        return jsonify({
            'error': 'Failed to process AI chat',
            'message': 'å¤„ç†AIå¯¹è¯æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•'
        }), 500

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))  # é»˜è®¤ç«¯å£5000
    print(f"ğŸš€ Flask TTS Server is running on port {port}")
    print(f"ğŸ“ TTS API: http://localhost:{port}")
    
    app.run(host='0.0.0.0', port=port, debug=True)
